{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevinMGII/Grupo7-Practica1/blob/main/Grupo7_Practica1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PRIMERA PRÁCTICA**. Predicción del Abandono de Empleados.\n",
        "\n",
        "Grupo 7. Miembros:\n",
        "\n",
        "*   *Kevin Medina García, 100495893.*\n",
        "*   *Bárbara Sánchez Moratalla, 100495857.*\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h-1-vZq4h3bq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "R-LvSCB-QJVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CARGA Y VISUALIZACIÓN DE LOS DATOS**\n",
        "\n",
        "En el desarrollo de esta práctica se utilizarán los archivos que contienen los datos con la extension **12**. Cumpliendo así las consideraciones generales, puesto que la suma de los últimos dos dígitos de nuestros NIA's es 12 en ambos casos."
      ],
      "metadata": {
        "id": "q070Vs_3PS_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación se lee el conjunto de datos y se muestran las primeras filas."
      ],
      "metadata": {
        "id": "6tMGD_R7QvOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "data_train = pd.read_csv(\"./attrition_availabledata_12.csv.gz\")                 # Cargamos el conjunto de datos de entrenamiento\n",
        "data_test = pd.read_csv(\"./attrition_competition_12.csv.gz\")                    # Cargamos el conjunto de datos de test utilizando el almacenamiento local de Google Colab.\n",
        "\n",
        "data_train.head()                                                               # Mostramos las 5 primeras filas del conjunto de datos de entrenamiento. (Not Working)\n",
        "data_test.head()                                                                # Mostramos las 5 primeras filas del conjunto de datos de test."
      ],
      "metadata": {
        "id": "CLcJTzTsyukm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "5d15cadd-fa53-4b96-f8ec-14202f52bcc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './attrition_availabledata_12.csv.gz'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-47923566fbb5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_columns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./attrition_availabledata_12.csv.gz\"\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;31m# Cargamos el conjunto de datos de entrenamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdata_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./attrition_competition_12.csv.gz\"\u001b[0m\u001b[0;34m)\u001b[0m                    \u001b[0;31m# Cargamos el conjunto de datos de test utilizando el almacenamiento local de Google Colab.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    763\u001b[0m                 \u001b[0;31m# error: Incompatible types in assignment (expression has type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                 \u001b[0;31m# \"GzipFile\", variable has type \"Union[str, BaseBuffer]\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m                 handle = gzip.GzipFile(  # type: ignore[assignment]\n\u001b[0m\u001b[1;32m    766\u001b[0m                     \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                     \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './attrition_availabledata_12.csv.gz'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ---"
      ],
      "metadata": {
        "id": "8Jb-ub5R0tOA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. EDA SIMPLIFICADO**\n",
        "\n",
        "A continuación, se realiza un Análisis Exploratorio de Datos (EDA). El objetivo es obtener una visión general del estado de los datos, permitiendo llevar a cabo algunos ajustes o limpiezas antes de empezar a utilizarlos.\n",
        "\n"
      ],
      "metadata": {
        "id": "NMJsAdKVholx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Número de  variables e instancias:**"
      ],
      "metadata": {
        "id": "cIfNYhm8jqxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_instancias, num_variables = data_train.shape                                # Usamos el atributo .shape de pandas para obtener la tupla (número de filas, número de columnas)\n",
        "print(f\"Número de instancias: {num_instancias}\")                                # Imprimimos num_instancias (número de filas)\n",
        "print(f\"Número de variables: {num_variables}\")                                  # Imprimimos num_variables (número de columnas)"
      ],
      "metadata": {
        "id": "OU6gEt1Ri767",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "677dd1ee-121b-4594-8678-3576b90ca506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de instancias: 2940\n",
            "Número de variables: 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El conjunto de datos con el que vamos a llevar a cabo esta práctica esta formado por 2940 instancias y 31 variables. Disponemos de una cantidad suficiente de datos como para entrenar un modelo de forma correcta."
      ],
      "metadata": {
        "id": "b_4ajhwqWqlC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tipos de variables (categóricas, numéricas u ordinales):**"
      ],
      "metadata": {
        "id": "Rp8GzujwjRse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_train.dtypes)                                                              # Mostramos los tipos de datos de cada columna del conjunto de datos de entrenamiento.\n",
        "\n",
        "                                                                                      # Seleccionamos los tipos de datos categóricos y numéricos con pandas\n",
        "categorical_vars = data_train.select_dtypes(include=['object', 'category']).columns   # Variables categóricas: aquellas de tipo 'object' o 'category'\n",
        "numeric_vars = data_train.select_dtypes(include=['int64', 'float64']).columns         # Variables numéricas: aquellas de tipo 'int64' o 'float64'\n",
        "\n",
        "print(\"Variables categóricas:\", categorical_vars)                                     # Imprimimos las variables categóricas\n",
        "print(\"Variables numéricas:\", numeric_vars)                                           # Imprimimos las variables numéricas\n",
        "# Las variables ordinales deben identificarse manualmente (mirar Nota)"
      ],
      "metadata": {
        "id": "ij6fgxDfjW68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e74e62c-b4a9-41b2-def2-59cd7bb1309e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hrs                        float64\n",
            "absences                     int64\n",
            "JobInvolvement               int64\n",
            "PerformanceRating            int64\n",
            "EnvironmentSatisfaction    float64\n",
            "JobSatisfaction            float64\n",
            "WorkLifeBalance            float64\n",
            "Age                          int64\n",
            "BusinessTravel              object\n",
            "Department                  object\n",
            "DistanceFromHome             int64\n",
            "Education                    int64\n",
            "EducationField              object\n",
            "EmployeeCount                int64\n",
            "EmployeeID                   int64\n",
            "Gender                      object\n",
            "JobLevel                     int64\n",
            "JobRole                     object\n",
            "MaritalStatus               object\n",
            "MonthlyIncome                int64\n",
            "NumCompaniesWorked         float64\n",
            "Over18                      object\n",
            "PercentSalaryHike            int64\n",
            "StandardHours                int64\n",
            "StockOptionLevel             int64\n",
            "TotalWorkingYears          float64\n",
            "TrainingTimesLastYear        int64\n",
            "YearsAtCompany               int64\n",
            "YearsSinceLastPromotion      int64\n",
            "YearsWithCurrManager         int64\n",
            "Attrition                   object\n",
            "dtype: object\n",
            "Variables categóricas: Index(['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole',\n",
            "       'MaritalStatus', 'Over18', 'Attrition'],\n",
            "      dtype='object')\n",
            "Variables numéricas: Index(['hrs', 'absences', 'JobInvolvement', 'PerformanceRating',\n",
            "       'EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance', 'Age',\n",
            "       'DistanceFromHome', 'Education', 'EmployeeCount', 'EmployeeID',\n",
            "       'JobLevel', 'MonthlyIncome', 'NumCompaniesWorked', 'PercentSalaryHike',\n",
            "       'StandardHours', 'StockOptionLevel', 'TotalWorkingYears',\n",
            "       'TrainingTimesLastYear', 'YearsAtCompany', 'YearsSinceLastPromotion',\n",
            "       'YearsWithCurrManager'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encontramos mayoritariamente variables numéricas en el conjunto de datos (23 variables numéricas frente a 8 variables categóricas)."
      ],
      "metadata": {
        "id": "T0_-MjDpxEYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Nota: pandas no es capaz de identificar variables ordinales automáticamente.*\n",
        "\n",
        "\n",
        "*Debemos analizar cada variable categórica y estudiar si existe un orden jerárquico entre los valores.*\n",
        "\n",
        "\n",
        "```\n",
        "# Ver valores únicos de la columna 'X' en el conjunto de entrenamiento\n",
        "print(data_train['X'].unique())\n",
        "```\n",
        "\n",
        "\n",
        "* BusinessTravel (Non-Travel, Travel_Rarely, Travel_Frequently) -> No\n",
        "* Department: (Sales, Research & Development, ...) -> No\n",
        "* EducationField (Marketing, Medical, Life Sciences, ...) -> No\n",
        "* Gender (Male, Female) -> No\n",
        "* JobRole (Research Director, Sales Executive, Laboratory Technician, ...) -> No\n",
        "* MaritalStatus (Single, Married, Divorced) -> No\n",
        "* Over18 (N, Y) -> No\n",
        "* Attrition (No, Yes) -> No\n",
        "\n",
        "*Concluimos que no hay variables ordinales.*"
      ],
      "metadata": {
        "id": "pot7rdkjqCri"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variables categóricas con alta cardinalidad:**"
      ],
      "metadata": {
        "id": "Xh_J_Ido5mVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in data_train.columns:                                                  # Recorremos las columnas del conjunto de datos: data_train\n",
        "    tipo_columna = data_train[col].dtype                                        # Almacenamos en una variable el tipo de dato de la columna actual\n",
        "    if tipo_columna == 'object' or tipo_columna.name == 'category':             # Check: ¿El tipo es un objeto, texto?, ¿El tipo es una categoría?\n",
        "        valores_unicos = data_train[col].unique()                               # Almacenamos en una variable los valores únicos de esa categoría\n",
        "        num_valores_unicos = len(valores_unicos)                                # Obtenemos la cantidad de valores únicos que hay\n",
        "        print(\"Cardinalidad de\", col, \":\", num_valores_unicos)                  # Mostramos la cardinalidad y el número de valores únicos por pantalla"
      ],
      "metadata": {
        "id": "UkXaUmRL529v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "8655c1fa-c800-4820-f4ee-c9d95c02789a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cardinalidad de BusinessTravel : 3\n",
            "Cardinalidad de Department : 3\n",
            "Cardinalidad de EducationField : 6\n",
            "Cardinalidad de Gender : 2\n",
            "Cardinalidad de JobRole : 9\n",
            "Cardinalidad de MaritalStatus : 3\n",
            "Cardinalidad de Over18 : 1\n",
            "Cardinalidad de Attrition : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El resultado obtenido nos indica que la mayoría de variables categóricas en el conjunto de datos presentan una baja cardinalidad. Sin embargo, algunas como \"JobRole\" tienen una alta cardinalidad con hasta 9 valores distintos.\n",
        "\n",
        "Además, se puede observar como \"Over18\" solamente tiene un valor, por lo que no aporta información relevante y debe ser eliminada."
      ],
      "metadata": {
        "id": "O9en_F_0TrGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variables con valores faltantes y cuántos son:**"
      ],
      "metadata": {
        "id": "OxDcVne_8vID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in data_train.columns:                                                  # Recorremos las columnas del conjunto de datos: data_train\n",
        "    contador_faltantes = 0                                                      # Inicializamos el contador de faltantes a 0\n",
        "    for valor in data_train[col]:                                               # Recorremos los valores de la columna\n",
        "        if valor is None or valor != valor:                                     # Check: ¿El valor es nulo (faltante)? Especial: valor != valor para detectar NaN\n",
        "            contador_faltantes += 1                                             # Incrementamos el contador de faltantes en una unidad\n",
        "    if contador_faltantes > 0:                                                  # Check: ¿Hay valores faltantes en esa columna?\n",
        "        print(\"Variable:\", col, \"- Valores faltantes:\", contador_faltantes)     # Mostramos la variable con sus faltantes por pantalla"
      ],
      "metadata": {
        "id": "TSgb4Y_8802p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fae9a7e-7a3c-480e-94e2-9f73f953c050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable: EnvironmentSatisfaction - Valores faltantes: 17\n",
            "Variable: JobSatisfaction - Valores faltantes: 8\n",
            "Variable: WorkLifeBalance - Valores faltantes: 23\n",
            "Variable: NumCompaniesWorked - Valores faltantes: 12\n",
            "Variable: TotalWorkingYears - Valores faltantes: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tras la ejecución, se puede observar como hay cinco variables presentes en el modelo que contienen valores faltantes, destacando alguna como \"WorkLifeBalance\" con hasta 23 valores no presentes, o \"EnvironmentSatisfaction\" con hasta 17.\n",
        "\n",
        "Durante el desarrollo de la práctica determinaremos qué estrategia seguir para solventar este problema, analizando el impacto de estas variables."
      ],
      "metadata": {
        "id": "8Wy1-YPVUVhy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Columnas constantes o columnas de ID:**"
      ],
      "metadata": {
        "id": "1bfk_Fyz-Bdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in data_train.columns:                                                  # Recorremos las columnas del conjunto de datos: data_train\n",
        "    valores_unicos = data_train[col].unique()                                   # Obtenemos los valores únicos de la columna\n",
        "    if len(valores_unicos) == 1 and valores_unicos[0] == valores_unicos[0]:     # Check: ¿La columna tiene un solo valor? Especial: ...[0] == ...[0] para detectar NaN\n",
        "        print(\"Variable:\", col, \"- Columna constante\")                          # Mostramos la variable con la columna constante\n",
        "    elif len(valores_unicos) == len(data_train):                                # Check: ¿El número de valores únicos es igual al número de filas?\n",
        "        print(\"Posible columna de ID:\", col)                                    # Mostramos la posible variable o columna de ID por pantalla"
      ],
      "metadata": {
        "id": "bDAr9gG697d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "7ac7af18-b7ed-4ae8-adfd-c99e03dfae82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable: EmployeeCount - Columna constante\n",
            "Posible columna de ID: EmployeeID\n",
            "Variable: Over18 - Columna constante\n",
            "Variable: StandardHours - Columna constante\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se identifican tres columnas constantes: \"EmployeeCount\", \"Over18\" y \"StandardHours\", así como una posible columna de id: \"EmployeeID\".\n",
        "\n",
        "Las columnas constantes no aportan información relevante o que resulte útil al modelo, y pueden eliminarse.\n",
        "\n",
        "La columna de id contiene valores únicos para cada fila, por lo que no contribuye al modelo y puede eliminarse."
      ],
      "metadata": {
        "id": "fvO5SCW1VzRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comprobación del tipo de problema: ¿clasificación o regresión?**"
      ],
      "metadata": {
        "id": "OWnO-qsyEW8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datos_col = data_train[\"Attrition\"]                                             # Seleccionamos la columna \"Attrition\" del conjunto de datos de entrenamiento\n",
        "valores_unicos = datos_col.unique()                                             # Obtenemos los valores únicos de la columna \"Attrition\"\n",
        "print(valores_unicos)                                                           # Mostramos los valores únicos por pantalla"
      ],
      "metadata": {
        "id": "hCwVgw45Ojre",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab3b56b-1187-4772-c166-f3edc53dbcfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No' 'Yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se puede observar en el resultado de la ejecución, se trata de un problema de clasificación binaria. El modelo podrá predecir una de las dos categorías: No, Yes."
      ],
      "metadata": {
        "id": "a-YOreL0QHKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Puesto que es un problema de clasificación, ¿está desbalanceado?**"
      ],
      "metadata": {
        "id": "7bOqly20RLro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datos_col = data_train[\"Attrition\"]                                             # Seleccionamos la columna \"Attrition\" del conjunto de datos de entrenamiento\n",
        "contador_clases = datos_col.value_counts()                                      # Contamos la cantidad de valores de cada clase en la columna \"Attrition\"\n",
        "print(contador_clases)                                                          # Mostramos la cantidad de valores de cada clase por pantalla"
      ],
      "metadata": {
        "id": "JWNqvKCSROPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f22d146-1f55-4866-af9f-858990a338f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attrition\n",
            "No     2466\n",
            "Yes     474\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concluimos el Análisis Exploratorio de Datos (EDA) indicando que el problema de clasificación está desbalanceado. Esto es debido a que existe una mayor cantidad de valores en una categoría: \"No\", respecto a la otra: \"Yes\".\n",
        "\n",
        "Un conjunto de datos desbalanceado puede provocar que el modelo aprenda mejor la categoría con mayor cantidad de valores y no aprenda correctamente la categoría con menor cantidad de valores.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "pvvVZ80_Rtol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. CÓMO SE VA A REALIZAR LA EVALUCIÓN**\n",
        "\n",
        "Tras realizar el EDA simplicado y observar que se trata de un problema de clasificación binaria desbalanceado, definimos en esta sección la estrategia de evaluación con la que entrenar y evaluar el modelo."
      ],
      "metadata": {
        "id": "j8l7X2xhU-s1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1. Evaluación Outer: Estimación del rendimiento futuro**\n",
        "\n",
        "La evaluación final del modelo se realizará con el método Holdout, por lo que dividiremos los datos en train (66.6%) y test (33.3%). Usaremos como semilla el NIA de uno de los miembros del grupo, como se exige en el enunciado.\n",
        "\n",
        "Además, al tratarse de un problema desbalanceado, es importante estratificar los resultados *(stratify=y)* a la hora de hacer la separación para tener para tener el mismo desbalance en el conjunto de entrenamiento y en el de prueba. De lo contrario, el conjunto de entrenamiento podría no reflejar la distribución real de 'Attrition' y resultar poco útil para entrenar el modelo."
      ],
      "metadata": {
        "id": "npBSJrtXVqyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y, random_state=100495893) # Dividimos en train y test\n",
        "print(\"Número de instancias de train:\", X_train.shape[0], \"instancias\")                                       # Imprimimos el número de instancias de entrenamiento\n",
        "print(\"Número de instancias de test:\", X_test.shape[0], \"instancias\")                                         # Imprimimos el número de instancias de test"
      ],
      "metadata": {
        "id": "UhFpEsFNVv2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para comprender los resultados emplearemos diversas métricas:\n",
        "* Accuracy: fracción de predicciones correctas (tanto positivas como negativas) sobre el total de predicciones.\n",
        "* TPR (True Positive Rate): fracción de positivos reales correctamente identificados.\n",
        "* TNR (True Negative Rate): fracción de negativos reales correctamente identificados.\n",
        "* Balanced Accuracy: media del TPR y TNR, útil para datasets desbalanceados.\n",
        "* Matriz de confusión: matriz que muestra la proporción de verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos."
      ],
      "metadata": {
        "id": "xtnx0dNNYFrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2. División en Train y Test**\n",
        "\n",
        "Antes de separar los datos en entrenamiento y test, limpiamos el conjunto de datos quitando aquellas variables que resultan irrelevantes, como se ha observado en el apartado segundo *(EmployeeID, EmployeeCount, Over18, StandardHours)*.\n",
        "\n",
        "También eliminamos la columna 'Attrition' de las features X, ya que 'Attrition' es la variable a predecir y de lo contrario se produciría data leakage, pues el modelo entrenara con los datos de evaluación.\n",
        "\n",
        "Por otro lado, debemos transformar las variables categóricas para que adopten valores numéricos. Para los casos en los que no hay relación entre los valores, se aplicará one-hot enconding; mientras que para los casos en los que sí, se mapearán de forma ordenada.\n",
        "\n",
        "Similarmente, debemos transformar la columna *Attrition* de los datos de test. Al tratarse de una variable binaria, conviene transformar sus valores categóricos (\"No\" y \"Yes\") en numéricos (0 y 1 respectivamente). Es decir, aplicamos label encoding."
      ],
      "metadata": {
        "id": "MT9L5XiM0X6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data_train.drop(columns=[\"EmployeeID\", \"EmployeeCount\", \"Over18\", \"StandardHours\", \"Attrition\"]) # Eliminamos para el conjunto train las columnas irrelevantes (y la columna de resultado 'Attrition')\n",
        "\n",
        "X = pd.get_dummies(X, columns=['Department', 'EducationField', 'JobRole'], drop_first=True)          # Transformamos variables categóricas a numéricas sin orden con one-hot encoding (creamos columnas extras para cada valor dentro de la columna)\n",
        "\n",
        "X.replace({                                                                                          # Transformamos variables categóricas a numéricas con orden\n",
        "    'BusinessTravel': {'Non-Travel': 0, 'Travel_Rarely': 1, 'Travel_Frequently': 2},\n",
        "    'Gender': {'Male': 0, 'Female': 1},\n",
        "    'MaritalStatus': {'Married': 0, 'Divorced': 1, 'Single': 2}\n",
        "}, inplace=True)\n",
        "\n",
        "y = data_train['Attrition'].map({'No': 0, 'Yes': 1})                                                 # Convertimos a valores binarios"
      ],
      "metadata": {
        "id": "SSNqW5zJ0eV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último, si X_train o y_train tienen valores NaN, el modelo puede quedarse atascado. En nuestro caso tenemos originalmente 47 NaN en train, los cuales rellenamos con la media."
      ],
      "metadata": {
        "id": "udYREOGp0vG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.isnull().sum().sum())  # Número total de NaN\n",
        "print(y_train.isnull().sum().sum())\n",
        "X_train.fillna(X_train.mean(), inplace=True)  # Rellena NaN con la media"
      ],
      "metadata": {
        "id": "S4AOej9R0zFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3. Evaluación Inner: Optimización de Hiperparámetros y Comparación de Modelos**\n",
        "\n",
        "La evaluación interna del modelo nos será útil para optimizar los hiperparámetros y elegir el mejor modelo.\n",
        "\n",
        "Para realizarla aplicaremos validación cruzada en el conjunto de datos de entrenamiento y, puesto que se trata de un problema desbalanceado, dicha validación será estratificada (cada partición conservará la misma proporción de clases que el conjunto original)."
      ],
      "metadata": {
        "id": "CB3eUrQ6Wc1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "xM9ZItER1N1z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. MÉTODOS BÁSICOS: KNN Y TREES**"
      ],
      "metadata": {
        "id": "Dm-R9-AEXKv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este apartado se llevará a cabo la evaluación de varios métodos de escalado e imputación utilizando K-Nearest Neighbors (KNN) como referencia. Mediante validación cruzada, se seleccionará la mejor combinación que se aplicará posteriormente."
      ],
      "metadata": {
        "id": "kQBGzP-7YssT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Escalado e imputación usando KNN:**\n",
        "\n"
      ],
      "metadata": {
        "id": "iNMheKfJafhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "inner_scores = {}                                                               # Diccionario para almacenar los resultados de cada combinación\n",
        "\n",
        "# Alternativa 1.1: KNN con StandardScaler ∧ Media\n",
        "pipeline_std_mean = Pipeline([                                                  # Creacion del Pipeline: Imputer: mean | Scaler: standard | KNN\n",
        "    ('imputer', SimpleImputer(strategy=\"mean\")),                                # Imputación de valores faltantes con la media\n",
        "    ('scaler', StandardScaler()),                                               # Escalado mediante StandardScaler\n",
        "    ('knn', KNeighborsClassifier())                                             # Clasificador K-Nearest Neighbors (KNN)\n",
        "])\n",
        "scores_std = cross_val_score(pipeline_std_mean, X, y, cv=cv_inner, scoring=\"balanced_accuracy\")             # Validación cruzada: usando cv_inner y balanced_accuracy (Apartado 3)\n",
        "inner_scores['KNN con StandardScaler ∧ Media'] = scores_std.mean()                                                  # Se almacena el resultado en el diccionario inner_scores{}\n",
        "\n",
        "# Alternativa 1.2: KNN con StandardScaler ∧ Mediana\n",
        "pipeline_std_median = Pipeline([                                                # Creacion del Pipeline: Imputer: mean | Scaler: standard | KNN\n",
        "    ('imputer', SimpleImputer(strategy=\"median\")),                              # Imputación de valores faltantes con la media\n",
        "    ('scaler', StandardScaler()),                                               # Escalado mediante StandardScaler\n",
        "    ('knn', KNeighborsClassifier())                                             # Clasificador K-Nearest Neighbors (KNN)\n",
        "])\n",
        "scores_std = cross_val_score(pipeline_std_median, X, y, cv=cv_inner, scoring=\"balanced_accuracy\")          # Validación cruzada: usando cv_inner y balanced_accuracy (Apartado 3)\n",
        "inner_scores['KNN con StandardScaler ∧ Mediana'] = scores_std.mean()                                               # Se almacena el resultado en el diccionario inner_scores{}\n",
        "\n",
        "# Alternativa 2.1: KNN con MinMaxScaler ∧ Media\n",
        "pipeline_minmax_mean = Pipeline([                                                    # Creacion del Pipeline: Imputer: mean | Scaler: minmax | KNN\n",
        "    ('imputer', SimpleImputer(strategy=\"mean\")),                                # Imputación de valores faltantes con la media\n",
        "    ('scaler', MinMaxScaler()),                                                 # Escalado mediante MinMaxScaler\n",
        "    ('knn', KNeighborsClassifier())                                             # Clasificador K-Nearest Neighbors (KNN)\n",
        "])\n",
        "scores_minmax = cross_val_score(pipeline_minmax_mean, X, y, cv=cv_inner, scoring=\"balanced_accuracy\")    # Validación cruzada: usando cv_inner y balanced_accuracy (Apartado 3)\n",
        "inner_scores['KNN con MinMaxScaler ∧ Media'] = scores_minmax.mean()                                              # Se almacena el resultado en el diccionario inner_scores{}\n",
        "\n",
        "# Alternativa 2.2: KNN con MinMaxScaler ∧ Mediana\n",
        "pipeline_minmax_median = Pipeline([                                                    # Creacion del Pipeline: Imputer: mean | Scaler: minmax | KNN\n",
        "    ('imputer', SimpleImputer(strategy=\"median\")),                              # Imputación de valores faltantes con la media\n",
        "    ('scaler', MinMaxScaler()),                                                 # Escalado mediante MinMaxScaler\n",
        "    ('knn', KNeighborsClassifier())                                             # Clasificador K-Nearest Neighbors (KNN)\n",
        "])\n",
        "scores_minmax = cross_val_score(pipeline_minmax_median, X, y, cv=cv_inner, scoring=\"balanced_accuracy\")    # Validación cruzada: usando cv_inner y balanced_accuracy (Apartado 3)\n",
        "inner_scores['KNN con MinMaxScaler ∧ Mediana'] = scores_minmax.mean()                                              # Se almacena el resultado en el diccionario inner_scores{}\n",
        "\n",
        "# Alternativa 3.1: KNN con RobustScaler ∧ Media\n",
        "pipeline_robust_mean = Pipeline([                                               # Creacion del Pipeline: Imputer: mean | Scaler: robustscaler | KNN\n",
        "    ('imputer', SimpleImputer(strategy=\"mean\")),                                # Imputación de valores faltantes con la media\n",
        "    ('scaler', RobustScaler()),                                                 # Escalado mediante RobustScaler\n",
        "    ('knn', KNeighborsClassifier())                                             # Clasificador K-Nearest Neighbors (KNN)\n",
        "])\n",
        "scores_robust = cross_val_score(pipeline_robust_mean, X, y, cv=cv_inner, scoring=\"balanced_accuracy\")    # Validación cruzada: usando cv_inner y balanced_accuracy (Apartado 3)\n",
        "inner_scores['KNN con RobustScaler ∧ Media'] = scores_robust.mean()                                              # Se almacena el resultado en el diccionario inner_scores{}\n",
        "\n",
        "# Alternativa 3.2: KNN con RobustScaler ∧ Mediana\n",
        "pipeline_robust_median = Pipeline([                                             # Creacion del Pipeline: Imputer: mean | Scaler: robustscaler | KNN\n",
        "    ('imputer', SimpleImputer(strategy=\"median\")),                              # Imputación de valores faltantes con la media\n",
        "    ('scaler', RobustScaler()),                                                 # Escalado mediante RobustScaler\n",
        "    ('knn', KNeighborsClassifier())                                             # Clasificador K-Nearest Neighbors (KNN)\n",
        "])\n",
        "scores_robust = cross_val_score(pipeline_robust_median, X, y, cv=cv_inner, scoring=\"balanced_accuracy\")    # Validación cruzada: usando cv_inner y balanced_accuracy (Apartado 3)\n",
        "inner_scores['KNN con RobustScaler ∧ Mediana'] = scores_robust.mean()                                              # Se almacena el resultado en el diccionario inner_scores{}\n",
        "\n",
        "# Mostrar los resultados\n",
        "for name, score in inner_scores.items():                                        # Se recorren las claves del diccionario\n",
        "    print(f\"{name}: {score}\")                                                   # Se imprime el nombre y el resultado\n",
        "\n",
        "mejor_metodo = \"\"                                                               # Variable para almacenar el mejor método\n",
        "mejor_puntuacion = 0                                                            # Variable para almacenar la mejor puntuación\n",
        "\n",
        "for metodo, puntuacion in inner_scores.items():                                 # Se recorren los pares clave-valor del diccionario\n",
        "    if puntuacion > mejor_puntuacion:                                           # Check: la puntuación actual es mejor que la mejor puntuación almacenada\n",
        "        mejor_puntuacion = puntuacion                                           # Se actualiza la mejor puntuación\n",
        "        mejor_metodo = metodo                                                   # Se actualiza el mejor método\n",
        "\n",
        "print(\"\\nEl mejor método seleccionado es:\", mejor_metodo)                         # Mostramos por pantalla el mejor método seleccionado"
      ],
      "metadata": {
        "id": "XLrTTK4Nafsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55547214-e8ea-4f22-e66b-54357d504ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN con StandardScaler ∧ Media: 0.6230156483123099\n",
            "KNN con StandardScaler ∧ Mediana: 0.6228128085557177\n",
            "KNN con MinMaxScaler ∧ Media: 0.6174301570946651\n",
            "KNN con MinMaxScaler ∧ Mediana: 0.6178358366078497\n",
            "KNN con RobustScaler ∧ Media: 0.6155035830247813\n",
            "KNN con RobustScaler ∧ Mediana: 0.615300743268189\n",
            "\n",
            "El mejor método seleccionado es: KNN con StandardScaler ∧ Media\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN y árboles**"
      ],
      "metadata": {
        "id": "Q4eloBh-M3vX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "lekzzJXQMSCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- KNN con hiperparámetros por omisión"
      ],
      "metadata": {
        "id": "3NRRSmu0MTRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_knn = Pipeline([                                                       # Creacion del Pipeline: Imputer: mean | Scaler: standard | KNN\n",
        "    ('imputer', SimpleImputer(strategy=\"mean\")),                                # Imputación de valores faltantes con la media\n",
        "    ('scaler', StandardScaler()),                                               # Escalado mediante StandardScaler\n",
        "    ('knn', KNeighborsClassifier())                                             # Clasificador K-Nearest Neighbors (KNN). Por defecto, n_neigbors = 5\n",
        "    ])\n",
        "\n",
        "inicio = time.time()                                                                           # Tiempo de inicio\n",
        "scores_KNN = cross_val_score(pipeline_knn, X, y, cv=cv_inner, scoring=\"balanced_accuracy\")     # Validación cruzada: usando cv_inner y balanced_accuracy\n",
        "print(scores_KNN)                                                                              # Muestra los resultados de la validación cruzada\n",
        "tiempo_KNN = time.time() - inicio                                                              # Tiempo de ejecución\n",
        "score_KNN = np.mean(scores_KNN)                                                                # Media de los resultados de la validación cruzada\n",
        "\n",
        "print(\"Score=\", score_KNN, \", Tiempo=\", tiempo_KNN, \"s\")                                       # Muestra el score y el tiempo de ejecución"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23pbx7OGMWXo",
        "outputId": "5ddf7c21-cdc5-4f89-e9ce-0f188c86b4cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.63831941 0.61877869 0.66272019 0.61757233 0.57768763]\n",
            "Score= 0.6230156483123099 , Tiempo= 0.3082764148712158 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Árbol de decisión con parámetros por omisión"
      ],
      "metadata": {
        "id": "1YrV09DXMY_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Classifier"
      ],
      "metadata": {
        "id": "nGBrz-vaMavr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "pipeline_dt = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy=\"mean\")),                                # Manejo de valores faltantes con la media\n",
        "    ('scaler', StandardScaler()),                                               # Estandarización de datos\n",
        "    ('dt', DecisionTreeClassifier())                                            # Árbol de decisión con pesos balanceados\n",
        "])\n",
        "\n",
        "inicio = time.time()                                                                      # Tiempo de inicio\n",
        "scores_DT = cross_val_score(pipeline_dt, X, y, cv=cv_inner, scoring=\"balanced_accuracy\")  # Validación cruzada: usando cv_inner y balanced_accuracy\n",
        "print(scores_DT)                                                                          # Muestra los resultados de la validación cruzada\n",
        "tiempo_DT = time.time() - inicio                                                          # Tiempo de ejecución\n",
        "score_DT = np.mean(scores_DT)                                                             # Media de los resultados de la validación cruzada\n",
        "\n",
        "print(\"Score=\", score_DT, \", Tiempo=\", tiempo_DT, \"s\")                          # Muestra el score y el tiempo de ejecución"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtR1F-iVMcEY",
        "outputId": "9c6e7ed3-c738-481e-c512-baa760b0d588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.89161426 0.84813708 0.88333511 0.84832924 0.85479876]\n",
            "Score= 0.8652428913917072 , Tiempo= 0.21794629096984863 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Classifier"
      ],
      "metadata": {
        "id": "TJgoTgIYMdZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "pipeline_rf = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy=\"mean\")),                                # Manejo de valores faltantes con la media\n",
        "    ('scaler', StandardScaler()),                                               # Estandarización de datos\n",
        "    ('rf', RandomForestClassifier())                                            # Árbol de decisión con pesos balanceados\n",
        "])\n",
        "\n",
        "inicio = time.time()                                                                        # Tiempo de inicio\n",
        "scores_RF = cross_val_score(pipeline_rf, X, y, cv=cv_inner, scoring=\"balanced_accuracy\")    # Validación cruzada: usando cv_inner y balanced_accuracy\n",
        "print(scores_RF)                                                                            # Muestra los resultados de la validación cruzada\n",
        "tiempo_RF = time.time() - inicio                                                            # Tiempo de ejecución\n",
        "score_RF = np.mean(scores_RF)                                                               # Media de los resultados de la validación cruzada\n",
        "\n",
        "print(\"Score=\", score_RF, \", Tiempo=\", tiempo_RF, \"s\")                          # Muestra el score y el tiempo de ejecución"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9f5IqDCMe91",
        "outputId": "425bd0b2-b411-4b32-ca2d-c71cdc06f32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.87259885 0.86315789 0.88319633 0.83157895 0.87793317]\n",
            "Score= 0.8656930369998657 , Tiempo= 3.0555663108825684 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balanced Random Forest"
      ],
      "metadata": {
        "id": "gPlpY2b2Mhb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "\n",
        "pipeline_brf = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy=\"mean\")),                                # Manejo de valores faltantes con la media\n",
        "    ('scaler', StandardScaler()),                                               # Estandarización de datos\n",
        "    ('brf', BalancedRandomForestClassifier())                                   # Árbol de decisión con pesos balanceados\n",
        "])\n",
        "\n",
        "inicio = time.time()                                                                        # Tiempo de inicio\n",
        "scores_BRF = cross_val_score(pipeline_brf, X, y, cv=cv_inner, scoring=\"balanced_accuracy\")  # Validación cruzada: usando cv_inner y balanced_accuracy\n",
        "print(scores_BRF)                                                                           # Muestra los resultados de la validación cruzada\n",
        "tiempo_BRF = time.time() - inicio                                                           # Tiempo de ejecución\n",
        "score_BRF = np.mean(scores_BRF)                                                             # Media de los resultados de la validación cruzada\n",
        "\n",
        "print(\"Score=\", score_BRF, \", Tiempo=\", tiempo_BRF, \"s\")                        # Muestra el score y el tiempo de ejecución"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgQjHcegMimQ",
        "outputId": "d90b5c66-5e18-4d7f-ac49-319dc456a922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.91213713 0.89893242 0.94997331 0.90666168 0.90926657]\n",
            "Score= 0.9153942253308747 , Tiempo= 2.220329999923706 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- KNN con ajuste de hiperparámetros"
      ],
      "metadata": {
        "id": "BuHvkwqKMkTC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZYmPX4yhMlNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Árbol de decisión con ajuste de hiperparámetros"
      ],
      "metadata": {
        "id": "y6iDetE0Ml7k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Classifier"
      ],
      "metadata": {
        "id": "LNMbASIzMo6O"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b_580j4AMpZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Classifier"
      ],
      "metadata": {
        "id": "zZgyyroLMp7k"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SMyOuSPQMtS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Balances Random Forest"
      ],
      "metadata": {
        "id": "IZYqItGeMuu3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0i6K_UczMv5N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}